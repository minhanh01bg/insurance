{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (14, 7)\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    '''\n",
    "    A class which implements linear regression model with gradient descent.\n",
    "    '''\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights, self.bias = None, None\n",
    "        self.loss = []\n",
    "        \n",
    "    @staticmethod\n",
    "    def _mean_squared_error(y, y_hat):\n",
    "        '''\n",
    "        Private method, used to evaluate loss at each iteration.\n",
    "        \n",
    "        :param: y - array, true values\n",
    "        :param: y_hat - array, predicted values\n",
    "        :return: float\n",
    "        '''\n",
    "        error = 0\n",
    "        for i in range(len(y)):\n",
    "            error += (y[i] - y_hat[i]) ** 2\n",
    "        return error / len(y)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Used to calculate the coefficient of the linear regression model.\n",
    "        \n",
    "        :param X: array, features\n",
    "        :param y: array, true values\n",
    "        :return: None\n",
    "        '''\n",
    "        # 1. Initialize weights and bias to zeros\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "        \n",
    "        # 2. Perform gradient descent\n",
    "        for i in range(self.n_iterations):\n",
    "            # Line equation\n",
    "            y_hat = np.dot(X, self.weights) + self.bias\n",
    "            loss = self._mean_squared_error(y, y_hat)\n",
    "            self.loss.append(loss)\n",
    "            \n",
    "            # Calculate derivatives\n",
    "            partial_w = (1 / X.shape[0]) * (2 * np.dot(X.T, (y_hat - y)))\n",
    "            partial_d = (1 / X.shape[0]) * (2 * np.sum(y_hat - y))\n",
    "            \n",
    "            # Update the coefficients\n",
    "            self.weights -= self.learning_rate * partial_w\n",
    "            self.bias -= self.learning_rate * partial_d\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Makes predictions using the line equation.\n",
    "        \n",
    "        :param X: array, features\n",
    "        :return: array, predictions\n",
    "        '''\n",
    "        return np.dot(X, self.weights) + self.bias\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a3ffae8020a817511732d4d0fe02060948831585d778b076daf6741c73f247a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
